{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb99cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e92d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import data_interface\n",
    "import mnar_blackout_lds\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac611d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "x_t, m_t, meta = data_interface.load_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf39e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_windows = data_interface.get_eval_windows(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbd4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def stratified_month_sampling(data, n_per_month, ts_key=\"blackout_start\"):\n",
    "    buckets = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        ts = item[ts_key]\n",
    "        month_key = (ts.year, ts.month)\n",
    "        buckets[month_key].append(item)\n",
    "\n",
    "    result = []\n",
    "    for month_key, items in buckets.items():\n",
    "        if len(items) < n_per_month:\n",
    "            picks = random.choices(items, k=n_per_month)\n",
    "        else:\n",
    "            picks = random.sample(items, n_per_month)\n",
    "        result.extend(picks)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7067708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1) Group evaluation windows by window_id and test_type/horizon\n",
    "#    (handles cases where there are multiple rows per window_id).\n",
    "# ------------------------------------------------------------------\n",
    "impute_by_id = {}\n",
    "forecast_1_by_id = {}\n",
    "forecast_3_by_id = {}\n",
    "forecast_6_by_id = {}\n",
    "\n",
    "for w in evaluation_windows:\n",
    "    wid = w[\"window_id\"]\n",
    "    if w[\"test_type\"] == \"impute\":\n",
    "        # If duplicates exist, last one wins â€“ that's fine for eval.\n",
    "        impute_by_id[wid] = w\n",
    "    elif w[\"test_type\"] == \"forecast\":\n",
    "        h = int(w[\"horizon_steps\"])\n",
    "        if h == 1:\n",
    "            forecast_1_by_id[wid] = w\n",
    "        elif h == 3:\n",
    "            forecast_3_by_id[wid] = w\n",
    "        elif h == 6:\n",
    "            forecast_6_by_id[wid] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b03b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 2) Keep only window_ids that have impute + 1-step + 3-step + 6-step\n",
    "# ------------------------------------------------------------------\n",
    "common_ids = (\n",
    "    set(impute_by_id.keys())\n",
    "    & set(forecast_1_by_id.keys())\n",
    "    & set(forecast_3_by_id.keys())\n",
    "    & set(forecast_6_by_id.keys())\n",
    ")\n",
    "\n",
    "# Pool of impute windows that have all matching forecast horizons\n",
    "impute_windows_pool = [impute_by_id[wid] for wid in common_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5618994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 3) Sample *validation* impute windows (stratified by month)\n",
    "# ------------------------------------------------------------------\n",
    "impute_evaluation_windows_val = stratified_month_sampling(\n",
    "    impute_windows_pool,\n",
    "    n_per_month=25,\n",
    "    ts_key=\"blackout_start\",\n",
    ")\n",
    "\n",
    "# Preserve order: we now build *aligned* forecast lists\n",
    "val_ids_ordered = [w[\"window_id\"] for w in impute_evaluation_windows_val]\n",
    "\n",
    "forecast_1_evaluation_windows_val = [\n",
    "    forecast_1_by_id[wid] for wid in val_ids_ordered\n",
    "]\n",
    "forecast_3_evaluation_windows_val = [\n",
    "    forecast_3_by_id[wid] for wid in val_ids_ordered\n",
    "]\n",
    "forecast_6_evaluation_windows_val = [\n",
    "    forecast_6_by_id[wid] for wid in val_ids_ordered\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5d8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(forecast_1_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "assert len(forecast_3_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "assert len(forecast_6_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Combined list used only for masking (deduped later)\n",
    "# ------------------------------------------------------------------\n",
    "evaluation_windows_val = (\n",
    "    forecast_1_evaluation_windows_val\n",
    "    + forecast_3_evaluation_windows_val\n",
    "    + forecast_6_evaluation_windows_val\n",
    "    + impute_evaluation_windows_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f861f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locf_impute_baseline(x_t, start_idx, end_idx, detector_idx):\n",
    "    \"\"\"\n",
    "    Naive 'last observation carried forward' baseline for imputation.\n",
    "    Uses the last finite value before blackout; falls back to\n",
    "    detector-wise historical mean if needed.\n",
    "    \"\"\"\n",
    "    last_idx = start_idx - 1\n",
    "    while last_idx >= 0 and not np.isfinite(x_t[last_idx, detector_idx]):\n",
    "        last_idx -= 1\n",
    "\n",
    "    if last_idx < 0:\n",
    "        det_vals = x_t[:, detector_idx]\n",
    "        last_val = float(np.nanmean(det_vals))\n",
    "    else:\n",
    "        last_val = float(x_t[last_idx, detector_idx])\n",
    "\n",
    "    length = end_idx - start_idx + 1\n",
    "    return np.full(length, last_val, dtype=float)\n",
    "\n",
    "\n",
    "def locf_forecast_baseline(x_t, end_idx, detector_idx):\n",
    "    \"\"\"\n",
    "    Naive baseline for forecasting: hold the last available observation\n",
    "    at the end of the blackout.\n",
    "    \"\"\"\n",
    "    last_idx = end_idx\n",
    "    while last_idx >= 0 and not np.isfinite(x_t[last_idx, detector_idx]):\n",
    "        last_idx -= 1\n",
    "\n",
    "    if last_idx < 0:\n",
    "        det_vals = x_t[:, detector_idx]\n",
    "        last_val = float(np.nanmean(det_vals))\n",
    "    else:\n",
    "        last_val = float(x_t[last_idx, detector_idx])\n",
    "\n",
    "    return last_val\n",
    "\n",
    "\n",
    "def evaluate_impute_forecast_model(\n",
    "    model,\n",
    "    mu_smooth,\n",
    "    Sigma_smooth,\n",
    "    mu_filt,\n",
    "    Sigma_filt,\n",
    "    x_t,\n",
    "    meta,\n",
    "    label=\"model\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Re-usable evaluation for any LDS-like model (MAR or MNAR):\n",
    "    - blackout imputation RMSE/MAE (length-weighted)\n",
    "    - 1 / 3 / 6-step forecast RMSE/MAE\n",
    "    \"\"\"\n",
    "    # ---------------- Imputation ----------------\n",
    "    impute_mae_list = []\n",
    "    impute_mse_list = []\n",
    "\n",
    "    for window in impute_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"impute\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "\n",
    "        eval_x_t = x_t[start_idx : end_idx + 1].copy()\n",
    "        eval_mu_smooth = mu_smooth[start_idx : end_idx + 1]\n",
    "        eval_Sigma_smooth = Sigma_smooth[start_idx : end_idx + 1]\n",
    "\n",
    "        reconstruct_x_t, _ = model.reconstruct_from_smoother(\n",
    "            eval_mu_smooth, eval_Sigma_smooth\n",
    "        )\n",
    "\n",
    "        y_true = eval_x_t[:, detector_idx]\n",
    "        y_pred = reconstruct_x_t[:, detector_idx]\n",
    "\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred[mask], y_true[mask])\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred[mask], y_true[mask])\n",
    "\n",
    "        impute_mae_list.append([mae, window[\"len_steps\"]])\n",
    "        impute_mse_list.append([mse, window[\"len_steps\"]])\n",
    "\n",
    "    final_mae = np.average(\n",
    "        [item[0] for item in impute_mae_list],\n",
    "        weights=[item[1] for item in impute_mae_list],\n",
    "    )\n",
    "    final_mse = np.average(\n",
    "        [item[0] for item in impute_mse_list],\n",
    "        weights=[item[1] for item in impute_mse_list],\n",
    "    )\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "    print(f\"\\n[{label}] Imputation performance:\")\n",
    "    print(\"  MAE :\", final_mae)\n",
    "    print(\"  MSE :\", final_mse)\n",
    "    print(\"  RMSE:\", final_rmse)\n",
    "\n",
    "    # ---------------- Forecasting ----------------\n",
    "    y_actual_1_step, y_forecast_1_step = [], []\n",
    "    y_actual_3_step, y_forecast_3_step = [], []\n",
    "    y_actual_6_step, y_forecast_6_step = [], []\n",
    "\n",
    "    forecast_evaluation_windows_val = (\n",
    "        forecast_1_evaluation_windows_val\n",
    "        + forecast_3_evaluation_windows_val\n",
    "        + forecast_6_evaluation_windows_val\n",
    "    )\n",
    "\n",
    "    for window in forecast_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"forecast\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "        horizon = int(window[\"horizon_steps\"])\n",
    "\n",
    "        # Skip windows too close to the end of the series\n",
    "        if end_idx + horizon >= x_t.shape[0]:\n",
    "            continue\n",
    "\n",
    "        eval_x_t = x_t[end_idx + 1 : end_idx + 1 + horizon].copy()\n",
    "\n",
    "        forecast_x_t, _ = model.k_step_forecast(\n",
    "            mu_filt, Sigma_filt, end_idx, k=horizon\n",
    "        )\n",
    "\n",
    "        y_true = eval_x_t[horizon - 1, detector_idx]\n",
    "        y_pred = forecast_x_t[detector_idx]\n",
    "\n",
    "        if not (np.isfinite(y_true) and np.isfinite(y_pred)):\n",
    "            continue\n",
    "\n",
    "        if horizon == 1:\n",
    "            y_forecast_1_step.append(y_pred)\n",
    "            y_actual_1_step.append(y_true)\n",
    "        elif horizon == 3:\n",
    "            y_forecast_3_step.append(y_pred)\n",
    "            y_actual_3_step.append(y_true)\n",
    "        elif horizon == 6:\n",
    "            y_forecast_6_step.append(y_pred)\n",
    "            y_actual_6_step.append(y_true)\n",
    "\n",
    "    mae_1_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    mse_1_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    rmse_1_step = np.sqrt(mse_1_step)\n",
    "\n",
    "    mae_3_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    mse_3_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    rmse_3_step = np.sqrt(mse_3_step)\n",
    "\n",
    "    mae_6_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    mse_6_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    rmse_6_step = np.sqrt(mse_6_step)\n",
    "\n",
    "    print(f\"\\n[{label}] Forecasting performance:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"1-step MAE :\", mae_1_step)\n",
    "    print(\"1-step MSE :\", mse_1_step)\n",
    "    print(\"1-step RMSE:\", rmse_1_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"3-step MAE :\", mae_3_step)\n",
    "    print(\"3-step MSE :\", mse_3_step)\n",
    "    print(\"3-step RMSE:\", rmse_3_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"6-step MAE :\", mae_6_step)\n",
    "    print(\"6-step MSE :\", mse_6_step)\n",
    "    print(\"6-step RMSE:\", rmse_6_step)\n",
    "\n",
    "    return {\n",
    "        \"impute_mae\": final_mae,\n",
    "        \"impute_mse\": final_mse,\n",
    "        \"impute_rmse\": final_rmse,\n",
    "        \"forecast_mae_1\": mae_1_step,\n",
    "        \"forecast_mse_1\": mse_1_step,\n",
    "        \"forecast_rmse_1\": rmse_1_step,\n",
    "        \"forecast_mae_3\": mae_3_step,\n",
    "        \"forecast_mse_3\": mse_3_step,\n",
    "        \"forecast_rmse_3\": rmse_3_step,\n",
    "        \"forecast_mae_6\": mae_6_step,\n",
    "        \"forecast_mse_6\": mse_6_step,\n",
    "        \"forecast_rmse_6\": rmse_6_step,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ec092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_locf_baseline(\n",
    "    x_t_true,\n",
    "    x_t_masked,\n",
    "    meta,\n",
    "    label=\"LOCF baseline\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Baseline evaluation using LOCF for both imputation and forecasting.\n",
    "    x_t_true   : full panel (no artificial masking), used ONLY for y_true\n",
    "    x_t_masked : panel with blackout windows masked (same as training),\n",
    "                 used for baseline predictions so it can't peek inside.\n",
    "    \"\"\"\n",
    "    # ---------- Imputation ----------\n",
    "    impute_mae_list = []\n",
    "    impute_mse_list = []\n",
    "\n",
    "    for window in impute_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"impute\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx   = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "\n",
    "        # Truth from full data\n",
    "        y_true = x_t_true[start_idx : end_idx + 1, detector_idx].copy()\n",
    "\n",
    "        # LOCF baseline only sees masked training panel\n",
    "        y_pred = locf_impute_baseline(\n",
    "            x_t_masked, start_idx, end_idx, detector_idx\n",
    "        )\n",
    "\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred[mask], y_true[mask])\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred[mask], y_true[mask])\n",
    "\n",
    "        impute_mae_list.append([mae, window[\"len_steps\"]])\n",
    "        impute_mse_list.append([mse, window[\"len_steps\"]])\n",
    "\n",
    "    final_mae = np.average(\n",
    "        [item[0] for item in impute_mae_list],\n",
    "        weights=[item[1] for item in impute_mae_list],\n",
    "    )\n",
    "    final_mse = np.average(\n",
    "        [item[0] for item in impute_mse_list],\n",
    "        weights=[item[1] for item in impute_mse_list],\n",
    "    )\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "    print(f\"\\n[{label}] Imputation performance:\")\n",
    "    print(\"  MAE :\", final_mae)\n",
    "    print(\"  MSE :\", final_mse)\n",
    "    print(\"  RMSE:\", final_rmse)\n",
    "\n",
    "    # ---------- Forecast ----------\n",
    "    y_actual_1_step, y_forecast_1_step = [], []\n",
    "    y_actual_3_step, y_forecast_3_step = [], []\n",
    "    y_actual_6_step, y_forecast_6_step = [], []\n",
    "\n",
    "    forecast_evaluation_windows_val = (\n",
    "        forecast_1_evaluation_windows_val\n",
    "        + forecast_3_evaluation_windows_val\n",
    "        + forecast_6_evaluation_windows_val\n",
    "    )\n",
    "\n",
    "    for window in forecast_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"forecast\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx   = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "        horizon = int(window[\"horizon_steps\"])\n",
    "\n",
    "        if end_idx + horizon >= x_t_true.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Truth from full data\n",
    "        y_true = x_t_true[end_idx + horizon, detector_idx]\n",
    "\n",
    "        # Baseline sees ONLY masked panel (so it uses last observed pre-blackout)\n",
    "        y_pred = locf_forecast_baseline(\n",
    "            x_t_masked, end_idx, detector_idx\n",
    "        )\n",
    "\n",
    "        if not (np.isfinite(y_true) and np.isfinite(y_pred)):\n",
    "            continue\n",
    "\n",
    "        if horizon == 1:\n",
    "            y_forecast_1_step.append(y_pred)\n",
    "            y_actual_1_step.append(y_true)\n",
    "        elif horizon == 3:\n",
    "            y_forecast_3_step.append(y_pred)\n",
    "            y_actual_3_step.append(y_true)\n",
    "        elif horizon == 6:\n",
    "            y_forecast_6_step.append(y_pred)\n",
    "            y_actual_6_step.append(y_true)\n",
    "\n",
    "    mae_1_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    mse_1_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    rmse_1_step = np.sqrt(mse_1_step)\n",
    "\n",
    "    mae_3_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    mse_3_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    rmse_3_step = np.sqrt(mse_3_step)\n",
    "\n",
    "    mae_6_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    mse_6_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    rmse_6_step = np.sqrt(mse_6_step)\n",
    "\n",
    "    print(f\"\\n[{label}] Forecasting performance:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"1-step MAE :\", mae_1_step)\n",
    "    print(\"1-step MSE :\", mse_1_step)\n",
    "    print(\"1-step RMSE:\", rmse_1_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"3-step MAE :\", mae_3_step)\n",
    "    print(\"3-step MSE :\", mse_3_step)\n",
    "    print(\"3-step RMSE:\", rmse_3_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"6-step MAE :\", mae_6_step)\n",
    "    print(\"6-step MSE :\", mse_6_step)\n",
    "    print(\"6-step RMSE:\", rmse_6_step)\n",
    "\n",
    "    return {\n",
    "        \"impute_mae\": final_mae,\n",
    "        \"impute_mse\": final_mse,\n",
    "        \"impute_rmse\": final_rmse,\n",
    "        \"forecast_mae_1\": mae_1_step,\n",
    "        \"forecast_mse_1\": mse_1_step,\n",
    "        \"forecast_rmse_1\": rmse_1_step,\n",
    "        \"forecast_mae_3\": mae_3_step,\n",
    "        \"forecast_mse_3\": mse_3_step,\n",
    "        \"forecast_rmse_3\": rmse_3_step,\n",
    "        \"forecast_mae_6\": mae_6_step,\n",
    "        \"forecast_mse_6\": mse_6_step,\n",
    "        \"forecast_rmse_6\": rmse_6_step,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ee64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_evaluation_windows(x_t, m_t, evaluation_windows_val, meta):\n",
    "    x_t_masked = x_t.copy()\n",
    "    m_t_masked = m_t.copy()\n",
    "\n",
    "    # Deduplicate (detector, start, end) so we don't re-mask the same block many times\n",
    "    unique_blocks = set()\n",
    "    for window in evaluation_windows_val:\n",
    "        start_ts = window[\"blackout_start\"]\n",
    "        end_ts = window[\"blackout_end\"]\n",
    "        det_id = window[\"detector_id\"]\n",
    "        unique_blocks.add((start_ts, end_ts, det_id))\n",
    "\n",
    "    for (start_ts, end_ts, det_id) in unique_blocks:\n",
    "        start_idx = np.where(meta[\"timestamps\"] == start_ts)[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == end_ts)[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == det_id)[0][0]\n",
    "\n",
    "        x_t_masked[start_idx:end_idx+1, detector_idx] = np.nan\n",
    "        m_t_masked[start_idx:end_idx+1, detector_idx] = 1\n",
    "\n",
    "    return x_t_masked, m_t_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4240d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data by masking evaluation windows\n",
    "x_t_train, m_t_train = mask_evaluation_windows(x_t, m_t, evaluation_windows_val, meta)\n",
    "latent_dim = 15\n",
    "D = x_t_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48fe311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EM iteration 1/7 ===\n",
      "  A norm: 3.796\n",
      "  Q trace: 6.143\n",
      "  mean diag(R): 41.217\n",
      "\n",
      "=== EM iteration 2/7 ===\n",
      "  A norm: 3.565\n",
      "  Q trace: 15.678\n",
      "  mean diag(R): 25.668\n",
      "  max relative param change: 4.606e-01\n",
      "\n",
      "=== EM iteration 3/7 ===\n",
      "  A norm: 3.613\n",
      "  Q trace: 18.437\n",
      "  mean diag(R): 22.976\n",
      "  max relative param change: 1.708e-01\n",
      "\n",
      "=== EM iteration 4/7 ===\n",
      "  A norm: 3.637\n",
      "  Q trace: 17.987\n",
      "  mean diag(R): 22.364\n",
      "  max relative param change: 1.034e-01\n",
      "\n",
      "=== EM iteration 5/7 ===\n",
      "  A norm: 3.650\n",
      "  Q trace: 16.519\n",
      "  mean diag(R): 22.119\n",
      "  max relative param change: 8.018e-02\n",
      "\n",
      "=== EM iteration 6/7 ===\n",
      "  A norm: 3.660\n",
      "  Q trace: 14.840\n",
      "  mean diag(R): 21.978\n",
      "  max relative param change: 6.312e-02\n",
      "\n",
      "=== EM iteration 7/7 ===\n",
      "  A norm: 3.666\n",
      "  Q trace: 13.350\n",
      "  mean diag(R): 21.897\n",
      "  max relative param change: 4.993e-02\n",
      "\n",
      "=== EM iteration 1/7 ===\n",
      "  A norm: 3.670\n",
      "  Q trace: 12.143\n",
      "  mean diag(R): 21.844\n",
      "\n",
      "=== EM iteration 2/7 ===\n",
      "  A norm: 3.669\n",
      "  Q trace: 11.003\n",
      "  mean diag(R): 21.809\n",
      "  max relative param change: 4.392e-02\n",
      "\n",
      "=== EM iteration 3/7 ===\n",
      "  A norm: 3.668\n",
      "  Q trace: 9.912\n",
      "  mean diag(R): 21.767\n",
      "  max relative param change: 4.439e-02\n",
      "\n",
      "=== EM iteration 4/7 ===\n",
      "  A norm: 3.668\n",
      "  Q trace: 8.970\n",
      "  mean diag(R): 21.723\n",
      "  max relative param change: 4.317e-02\n",
      "\n",
      "=== EM iteration 5/7 ===\n",
      "  A norm: 3.668\n",
      "  Q trace: 8.184\n",
      "  mean diag(R): 21.678\n",
      "  max relative param change: 4.125e-02\n",
      "\n",
      "=== EM iteration 6/7 ===\n",
      "  A norm: 3.668\n",
      "  Q trace: 7.520\n",
      "  mean diag(R): 21.633\n",
      "  max relative param change: 3.951e-02\n",
      "\n",
      "=== EM iteration 7/7 ===\n",
      "  A norm: 3.669\n",
      "  Q trace: 6.966\n",
      "  mean diag(R): 21.591\n",
      "  max relative param change: 3.647e-02\n"
     ]
    }
   ],
   "source": [
    "# ---------------- MAR model (no phi updates) ----------------\n",
    "mar_params = mnar_blackout_lds.MNARParams.init_random(K=latent_dim, D=D, seed=42)\n",
    "model_mar = mnar_blackout_lds.MNARBlackoutLDS(mar_params)\n",
    "em_train_history_mar = model_mar.em_train(\n",
    "    x_t_train,\n",
    "    m_t_train,\n",
    "    num_iters=7,\n",
    "    update_phi=False,  # MAR: ignore missingness mechanism\n",
    "    phi_steps=0,\n",
    "    phi_lr=0.0,\n",
    "    verbose=True,\n",
    "    convergence_tol=1e-3,\n",
    ")\n",
    "\n",
    "# ---------------- MNAR model (warm-start from MAR) ----------------\n",
    "mnar_params = copy.deepcopy(model_mar.params)\n",
    "model_mnar = mnar_blackout_lds.MNARBlackoutLDS(mnar_params)\n",
    "em_train_history_mnar = model_mnar.em_train(\n",
    "    x_t_train,\n",
    "    m_t_train,\n",
    "    num_iters=7,\n",
    "    update_phi=True,   # MNAR: learn missingness mechanism\n",
    "    phi_steps=3,\n",
    "    phi_lr=1e-4,\n",
    "    verbose=True,\n",
    "    convergence_tol=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee32f79",
   "metadata": {},
   "source": [
    "### Reconstruction and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c390c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MAR LDS] Imputation performance:\n",
      "  MAE : 3.399999466734165\n",
      "  MSE : 21.673734315816315\n",
      "  RMSE: 4.6555058066569215\n",
      "\n",
      "[MAR LDS] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 4.7588700967088196\n",
      "1-step MSE : 44.34827930368862\n",
      "1-step RMSE: 6.65945037549561\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 4.093099847700625\n",
      "3-step MSE : 34.61601105321269\n",
      "3-step RMSE: 5.8835372908831545\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 4.437011528011764\n",
      "6-step MSE : 42.31649291595266\n",
      "6-step RMSE: 6.505112828841069\n"
     ]
    }
   ],
   "source": [
    "ekf_mar = model_mar.ekf_forward(x_t_train, m_t_train)\n",
    "smoother_mar = model_mar.rts_smoother(ekf_mar)\n",
    "\n",
    "mu_filt_mar = ekf_mar[\"mu_filt\"]\n",
    "Sigma_filt_mar = ekf_mar[\"Sigma_filt\"]\n",
    "mu_smooth_mar = smoother_mar[\"mu_smooth\"]\n",
    "Sigma_smooth_mar = smoother_mar[\"Sigma_smooth\"]\n",
    "\n",
    "metrics_mar = evaluate_impute_forecast_model(\n",
    "    model=model_mar,\n",
    "    mu_smooth=mu_smooth_mar,\n",
    "    Sigma_smooth=Sigma_smooth_mar,\n",
    "    mu_filt=mu_filt_mar,\n",
    "    Sigma_filt=Sigma_filt_mar,\n",
    "    x_t=x_t,\n",
    "    meta=meta,\n",
    "    label=\"MAR LDS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ad9cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MNAR LDS] Imputation performance:\n",
      "  MAE : 3.0274329967627325\n",
      "  MSE : 19.05592235559149\n",
      "  RMSE: 4.365308964505433\n",
      "\n",
      "[MNAR LDS] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 4.34684584924599\n",
      "1-step MSE : 38.65333938590866\n",
      "1-step RMSE: 6.217180983846992\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 3.489478736638445\n",
      "3-step MSE : 27.885899684428434\n",
      "3-step RMSE: 5.280710149632191\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 3.860714902812001\n",
      "6-step MSE : 33.501399851512396\n",
      "6-step RMSE: 5.7880393788840445\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Reconstruction & prediction: MNAR ----------------\n",
    "ekf_mnar = model_mnar.ekf_forward(x_t_train, m_t_train)\n",
    "smoother_mnar = model_mnar.rts_smoother(ekf_mnar)\n",
    "\n",
    "mu_filt_mnar = ekf_mnar[\"mu_filt\"]\n",
    "Sigma_filt_mnar = ekf_mnar[\"Sigma_filt\"]\n",
    "mu_smooth_mnar = smoother_mnar[\"mu_smooth\"]\n",
    "Sigma_smooth_mnar = smoother_mnar[\"Sigma_smooth\"]\n",
    "\n",
    "metrics_mnar = evaluate_impute_forecast_model(\n",
    "    model=model_mnar,\n",
    "    mu_smooth=mu_smooth_mnar,\n",
    "    Sigma_smooth=Sigma_smooth_mnar,\n",
    "    mu_filt=mu_filt_mnar,\n",
    "    Sigma_filt=Sigma_filt_mnar,\n",
    "    x_t=x_t,\n",
    "    meta=meta,\n",
    "    label=\"MNAR LDS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f890c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LOCF baseline] Imputation performance:\n",
      "  MAE : 3.701672288083485\n",
      "  MSE : 24.841926859359603\n",
      "  RMSE: 4.984167619508758\n",
      "\n",
      "[LOCF baseline] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 4.762612556501439\n",
      "1-step MSE : 48.416818803912086\n",
      "1-step RMSE: 6.958219513921078\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 4.177777069165959\n",
      "3-step MSE : 31.36509333346946\n",
      "3-step RMSE: 5.60045474345338\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 4.033777534055315\n",
      "6-step MSE : 27.962783569499322\n",
      "6-step RMSE: 5.2879848306797665\n",
      "\n",
      "Done: LOCF vs MAR vs MNAR evaluated on the same blackout windows.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Baseline: LOCF ----------------\n",
    "baseline_locf_metrics = evaluate_locf_baseline(\n",
    "    x_t_true=x_t,\n",
    "    x_t_masked=x_t_train,\n",
    "    meta=meta,\n",
    "    label=\"LOCF baseline\",\n",
    ")\n",
    "\n",
    "print(\"\\nDone: LOCF vs MAR vs MNAR evaluated on the same blackout windows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
